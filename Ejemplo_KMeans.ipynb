{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# Celda 1: Título y objetivos\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"# Análisis de Clustering con K-Means: Caso Titanic\n",
    "\n",
    "Este cuaderno tiene fines educativos y te guiará por el flujo clásico de un análisis de clustering con el algoritmo **K-Means**, usando el famoso set de datos del Titanic.\n",
    "\n",
    "**Objetivos:**\n",
    "- Preparar y escalar datos.\n",
    "- Identificar el número óptimo de clústers usando diferentes métricas (Elbow, Silhouette, Gap).\n",
    "- Aplicar el algoritmo K-Means.\n",
    "- Visualizar y analizar los resultados.\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 2: Teoría básica sobre K-Means\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "## ¿Qué es K-Means?\n",
    "\n",
    "**K-Means** es un algoritmo de *clustering* no supervisado que tiene como objetivo dividir un conjunto de datos en *k* grupos (clusters) homogéneos según sus características. El procedimiento es:\n",
    "\n",
    "1. Inicializar aleatoriamente k centroides.\n",
    "2. Asignar cada punto de datos al centroide más cercano.\n",
    "3. Recalcular la posición de cada centroide como la media de los puntos asignados a cada uno.\n",
    "4. Repetir los pasos 2-3 hasta que los centroides ya no cambien significativamente.\n",
    "\n",
    "**¿Para qué sirve?**  \n",
    "Para encontrar grupos \"naturales\" en los datos, identificar segmentos de usuarios, patrones de consumo, etc.\n",
    "\n",
    "**Limitaciones**:\n",
    "- Hay que definir k (cantidad de clusters) antes de ejecutar el algoritmo.\n",
    "- No funciona bien si los clusters tienen formas no esféricas o tamaños muy diferentes.\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 3: Librerías y carga de datos\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Cargamos el dataset Titanic desde la web\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 4: Limpieza y selección de variables\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "## Preparación y Escalado de los Datos\n",
    "\n",
    "Seleccionamos solo variables numéricas para el clustering y completamos valores nulos.\n",
    "\"\"\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "df_features = df[features].copy()\n",
    "\n",
    "# Completamos nulos en 'Age' con la media\n",
    "df_features['Age'] = df_features['Age'].fillna(df_features['Age'].mean())\n",
    "df_features.isnull().sum()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 5: Escalado de datos\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_features)\n",
    "\n",
    "pd.DataFrame(X_scaled, columns=features).head()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 6: Selección del número óptimo de clusters\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "## ¿Cuántos clusters elegir?  \n",
    "Utilizaremos tres métodos: **Elbow (Codo)**, **Silhouette (Silueta)** y (opcional) **Gap Statistic**.\n",
    "\"\"\"))\n",
    "\n",
    "# Elbow\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "inertia = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(K, inertia, 'o-')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('Método del codo (Elbow)')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# Silhouette\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "silhouette_scores = []\n",
    "K2 = range(2, 11)\n",
    "for k in K2:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(K2, silhouette_scores, 'o-')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Score de silueta')\n",
    "plt.title('Método de la Silueta')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda teoría gap statistic\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "> El método **Gap Statistic** compara la inercia de los clusters reales con la inercia obtenida en datos simulados aleatorios, ayudando a determinar si los clusters encontrados son significativamente mejores que una partición aleatoria.  \n",
    "> Por simplicidad, lo omitimos aquí, pero puedes consultarlo si tienes instalado el paquete `gap-stat`.\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 7: Implementación de K-Means\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "## Aplicando K-Means con el número óptimo de clusters\n",
    "\n",
    "Según los gráficos anteriores, elige el valor de k más adecuado (por ejemplo, 3 o 4) y entrena el modelo.\n",
    "\"\"\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "k_opt = 3  # Cambia según los resultados obtenidos arriba\n",
    "kmeans = KMeans(n_clusters=k_opt, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "df['Cluster'] = labels\n",
    "df['Cluster'].value_counts()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 8: Gráficos y análisis de resultados\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "## Análisis y Visualización de los Clusters\n",
    "\n",
    "Veamos cómo se distribuyen las variables según cada cluster.\n",
    "\"\"\"))\n",
    "for feature in ['Age', 'Fare', 'SibSp', 'Parch']:\n",
    "    cells.append(nbf.v4.new_code_cell(f\"\"\"\\\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.boxplot(x='Cluster', y='{feature}', data=df)\n",
    "plt.title('Boxplot de {feature} por cluster')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "# Estadísticas promedio por cluster\n",
    "df.groupby('Cluster')[['Age', 'Fare', 'SibSp', 'Parch']].mean()\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 9: Interpretación de resultados\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "### Interpretación de los resultados\n",
    "\n",
    "- Observa si los clusters se diferencian claramente según edad, tarifa, hermanos o hijos a bordo.\n",
    "- Preguntas guía:\n",
    "    - ¿Hay clusters que agrupan pasajeros más jóvenes?\n",
    "    - ¿Hay grupos que tienden a pagar más tarifa?\n",
    "    - ¿Algún cluster concentra familias grandes?\n",
    "- Estos patrones pueden relacionarse con clases sociales, tipo de ticket, o características familiares de los pasajeros.\n",
    "\n",
    "**Recuerda:** En clustering, la interpretación depende mucho del contexto del negocio y puede requerir analizar más variables o combinar con datos categóricos (por ejemplo, sexo, clase).\n",
    "\"\"\"))\n",
    "\n",
    "# Celda 10: Visualización PCA (adicional)\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\\\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=labels, palette='Set2')\n",
    "plt.title('Clusters visualizados en el plano PCA')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_markdown_cell(\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
